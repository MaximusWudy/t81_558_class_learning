{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m0HWxcHskn4O"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_5_bootstrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GwoHV43Ukn4Q"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "**Module 5: Regularization and Dropout**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pNcea-drkn4Q"
      },
      "source": [
        "# Module 5 Material\n",
        "\n",
        "* Part 5.1: Part 5.1: Introduction to Regularization: Ridge and Lasso [[Video]](https://www.youtube.com/watch?v=jfgRtCYjoBs&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_1_reg_ridge_lasso.ipynb)\n",
        "* Part 5.2: Using K-Fold Cross Validation with Keras [[Video]](https://www.youtube.com/watch?v=maiQf8ray_s&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_2_kfold.ipynb)\n",
        "* Part 5.3: Using L1 and L2 Regularization with Keras to Decrease Overfitting [[Video]](https://www.youtube.com/watch?v=JEWzWv1fBFQ&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_3_keras_l1_l2.ipynb)\n",
        "* Part 5.4: Drop Out for Keras to Decrease Overfitting [[Video]](https://www.youtube.com/watch?v=bRyOi0L6Rs8&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_4_dropout.ipynb)\n",
        "* **Part 5.5: Benchmarking Keras Deep Learning Regularization Techniques** [[Video]](https://www.youtube.com/watch?v=1NLBwPumUAs&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_5_bootstrap.ipynb)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fqyUhlDhkn4Q"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running the correct version of TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsN_BrNTkn4R",
        "outputId": "720ef567-d8c5-4208-f704-545fc247294c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rcplr2pVkn4S"
      },
      "source": [
        "# Part 5.5: Benchmarking Regularization Techniques\n",
        "\n",
        "Quite a few hyperparameters have been introduced so far.  Tweaking each of these values can have an effect on the score obtained by your neural networks.  Some of the hyperparameters seen so far include:\n",
        "\n",
        "* Number of layers in the neural network\n",
        "* How many neurons in each layer\n",
        "* What activation functions to use on each layer\n",
        "* Dropout percent on each layer\n",
        "* L1 and L2 values on each layer\n",
        "\n",
        "To try out each of these hyperparameters you will need to run train neural networks with multiple settings for each hyperparameter.  However, you may have noticed that neural networks often produce somewhat different results when trained multiple times.  This is because the neural networks start with random weights.  Because of this it is necessary to fit and evaluate a neural network times to ensure that one set of hyperparameters are actually better than another.  Bootstrapping can be an effective means of benchmarking (comparing) two sets of hyperparameters.  \n",
        "\n",
        "Bootstrapping is similar to cross-validation.  Both go through a number of cycles/folds providing validation and training sets.  However, bootstrapping can have an unlimited number of cycles.  **Bootstrapping chooses a new train and validation split each cycle, with replacement.**  The fact that each cycle is chosen with replacement means that, unlike cross validation, there will often be repeated rows selected between cycles.  If you run the bootstrap for enough cycles, there will be duplicate cycles.\n",
        "\n",
        "In this part **we will use bootstrapping for hyperparameter benchmarking**.  We will train a neural network for a specified number of splits (denoted by the SPLITS constant).  For these examples we use 100.  We will compare the average score at the end of the 100.  By the end of the cycles the mean score will have converged somewhat.  This ending score will be a much better basis of comparison than a single cross-validation.  Additionally, the average number of epochs will be tracked to give an idea of a possible optimal value.  **Because the early stopping validation set is also used to evaluate the the neural network as well, it might be slightly inflated.**  This is because we are both stopping and evaluating on the same sample.  However, we are using the scores only as relative measures to determine the superiority of one set of hyperparameters to another, so this slight inflation should not present too much of a problem.\n",
        "\n",
        "Because we are **benchmarking**, we will display the amount of time taken for each cycle.  The following function can be used to nicely format a time span."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k_xChO0Fkn4S"
      },
      "outputs": [],
      "source": [
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# another way to use quotient and remainder\n",
        "def hms_string2(sec_elapsed):\n",
        "    h = sec_elapsed // (60 * 60)\n",
        "    m = (sec_elapsed % (60 * 60)) // 60\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:59:26.00\n",
            "0:59:26.00\n"
          ]
        }
      ],
      "source": [
        "print(hms_string(3566))\n",
        "print(hms_string2(3566))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IOBKcIUzkn4T"
      },
      "source": [
        "## Bootstrapping for Regression\n",
        "\n",
        "Regression bootstrapping uses the **ShuffleSplit** object to perform the splits.  This technique is similar to **KFold** for cross-validation; no balancing occurs.  We will attempt to predict the age column for the **jh-simple-dataset**; the following code loads this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yWKzWCRskn4T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for product\n",
        "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
        "df.drop('product', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('age').drop('id')\n",
        "x = df[x_columns].values\n",
        "y = df['age'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2000 records in the dataset.\n"
          ]
        }
      ],
      "source": [
        "print(f\"There are {df.shape[0]} records in the dataset.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2mHk4XHLkn4T"
      },
      "source": [
        "The following code performs the bootstrap.  The architecture of the neural network can be adjusted to compare many different configurations. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Why do we use multiple epochs? \n",
        "\n",
        "Researchers want to **get good performance** on non-training data (in practice this can be approximated with a hold-out set); usually (but not always) that **takes more than one pass over the training data**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbhxDX1rkn4U",
        "outputId": "45488bc1-c828-42ec-ebb5-f5b569fa96d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#1: score=0.564756, mean score=0.564756, stdev=0.000000  epochs=103, mean epochs=103  time=0:00:09.83\n",
            "#2: score=1.075044, mean score=0.819900, stdev=0.255144  epochs=78, mean epochs=90  time=0:00:05.71\n",
            "#3: score=0.691080, mean score=0.776960, stdev=0.216995  epochs=113, mean epochs=98  time=0:00:08.02\n",
            "#4: score=0.839858, mean score=0.792685, stdev=0.189886  epochs=103, mean epochs=99  time=0:00:07.31\n",
            "#5: score=0.608902, mean score=0.755928, stdev=0.185066  epochs=132, mean epochs=105  time=0:00:09.27\n",
            "#6: score=4.186223, mean score=1.327644, stdev=1.289510  epochs=874, mean epochs=233  time=0:00:58.56\n",
            "#7: score=0.711049, mean score=1.239559, stdev=1.213195  epochs=125, mean epochs=218  time=0:00:08.74\n",
            "#8: score=0.469667, mean score=1.143322, stdev=1.163053  epochs=132, mean epochs=207  time=0:00:09.57\n",
            "#9: score=0.645715, mean score=1.088033, stdev=1.107632  epochs=133, mean epochs=199  time=0:00:09.49\n",
            "#10: score=0.996806, mean score=1.078910, stdev=1.051148  epochs=130, mean epochs=192  time=0:00:08.98\n",
            "#11: score=1.000964, mean score=1.071824, stdev=1.002481  epochs=88, mean epochs=182  time=0:00:06.19\n",
            "#12: score=0.944381, mean score=1.061204, stdev=0.960449  epochs=115, mean epochs=177  time=0:00:08.06\n",
            "#13: score=0.612510, mean score=1.026689, stdev=0.930483  epochs=128, mean epochs=173  time=0:00:08.84\n",
            "#14: score=1.168085, mean score=1.036789, stdev=0.897375  epochs=84, mean epochs=167  time=0:00:06.06\n",
            "#15: score=0.636118, mean score=1.010077, stdev=0.872689  epochs=111, mean epochs=163  time=0:00:07.68\n",
            "#16: score=0.730017, mean score=0.992573, stdev=0.847692  epochs=138, mean epochs=161  time=0:00:09.46\n",
            "#17: score=0.740375, mean score=0.977738, stdev=0.824520  epochs=123, mean epochs=159  time=0:00:08.63\n",
            "#18: score=1.079756, mean score=0.983406, stdev=0.801630  epochs=101, mean epochs=156  time=0:00:07.82\n",
            "#19: score=0.845381, mean score=0.976141, stdev=0.780858  epochs=129, mean epochs=154  time=0:00:09.15\n",
            "#20: score=0.653725, mean score=0.960021, stdev=0.764323  epochs=134, mean epochs=153  time=0:00:09.62\n",
            "#21: score=0.680075, mean score=0.946690, stdev=0.748282  epochs=99, mean epochs=151  time=0:00:07.11\n",
            "#22: score=0.523046, mean score=0.927433, stdev=0.736384  epochs=125, mean epochs=149  time=0:00:08.75\n",
            "#23: score=0.575220, mean score=0.912120, stdev=0.723771  epochs=181, mean epochs=151  time=0:00:12.79\n",
            "#24: score=0.767054, mean score=0.906075, stdev=0.709125  epochs=177, mean epochs=152  time=0:00:12.26\n",
            "#25: score=0.621548, mean score=0.894694, stdev=0.697031  epochs=127, mean epochs=151  time=0:00:09.11\n",
            "#26: score=0.710481, mean score=0.887609, stdev=0.684413  epochs=97, mean epochs=149  time=0:00:07.04\n",
            "#27: score=0.659366, mean score=0.879156, stdev=0.673000  epochs=123, mean epochs=148  time=0:00:09.29\n",
            "#28: score=0.697047, mean score=0.872652, stdev=0.661737  epochs=105, mean epochs=146  time=0:00:07.67\n",
            "#29: score=0.581253, mean score=0.862604, stdev=0.652398  epochs=100, mean epochs=145  time=0:00:07.82\n",
            "#30: score=0.637054, mean score=0.855085, stdev=0.642709  epochs=125, mean epochs=144  time=0:00:09.34\n",
            "#31: score=0.670173, mean score=0.849120, stdev=0.633101  epochs=119, mean epochs=143  time=0:00:08.13\n",
            "#32: score=0.552234, mean score=0.839843, stdev=0.625268  epochs=146, mean epochs=143  time=0:00:09.44\n",
            "#33: score=0.882945, mean score=0.841149, stdev=0.615766  epochs=79, mean epochs=141  time=0:00:05.29\n",
            "#34: score=1.196232, mean score=0.851592, stdev=0.609602  epochs=101, mean epochs=140  time=0:00:06.60\n",
            "#35: score=0.673664, mean score=0.846509, stdev=0.601561  epochs=130, mean epochs=140  time=0:00:08.32\n",
            "#36: score=0.654732, mean score=0.841182, stdev=0.593984  epochs=117, mean epochs=139  time=0:00:07.66\n",
            "#37: score=1.074670, mean score=0.847492, stdev=0.587124  epochs=102, mean epochs=138  time=0:00:06.62\n",
            "#38: score=0.752576, mean score=0.844994, stdev=0.579547  epochs=108, mean epochs=137  time=0:00:07.01\n",
            "#39: score=0.620562, mean score=0.839240, stdev=0.573167  epochs=120, mean epochs=137  time=0:00:07.69\n",
            "#40: score=0.598632, mean score=0.833224, stdev=0.567202  epochs=148, mean epochs=137  time=0:00:09.69\n",
            "#41: score=1.159042, mean score=0.841171, stdev=0.562493  epochs=138, mean epochs=137  time=0:00:08.87\n",
            "#42: score=0.464216, mean score=0.832196, stdev=0.558719  epochs=143, mean epochs=137  time=0:00:09.15\n",
            "#43: score=0.620778, mean score=0.827279, stdev=0.553103  epochs=102, mean epochs=136  time=0:00:06.64\n",
            "#44: score=0.615190, mean score=0.822459, stdev=0.547694  epochs=108, mean epochs=136  time=0:00:07.01\n",
            "#45: score=1.111363, mean score=0.828879, stdev=0.543246  epochs=105, mean epochs=135  time=0:00:06.87\n",
            "#46: score=0.706473, mean score=0.826218, stdev=0.537606  epochs=94, mean epochs=134  time=0:00:06.18\n",
            "#47: score=0.596528, mean score=0.821331, stdev=0.532887  epochs=109, mean epochs=134  time=0:00:07.07\n",
            "#48: score=0.819142, mean score=0.821286, stdev=0.527307  epochs=84, mean epochs=133  time=0:00:05.57\n",
            "#49: score=0.819645, mean score=0.821252, stdev=0.521899  epochs=118, mean epochs=132  time=0:00:07.75\n",
            "#50: score=0.831359, mean score=0.821454, stdev=0.516656  epochs=105, mean epochs=132  time=0:00:07.14\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "SPLITS = 50\n",
        "\n",
        "# Bootstrap\n",
        "boot = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=42)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    \n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=5, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    # batch_size = When None or unspecified, it will default to 32\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "    \n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(x_test)\n",
        "  \n",
        "    # Measure this bootstrap's log loss\n",
        "    score = np.sqrt(metrics.mean_squared_error(pred,y_test)) # RMSE\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark) # this will be an accumulative mean, along with # of splits\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark) # returns the population standard deviation\n",
        "    \n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},\"\n",
        "          f\" stdev={mdev:.6f}\", \n",
        "          f\" epochs={epochs}, mean epochs={int(m2)}\", \n",
        "          f\" time={hms_string(time_took)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QIFZhOuykn4U"
      },
      "source": [
        "The bootstrapping process for classification is similar, and I present it in the next section.\n",
        "\n",
        "## Bootstrapping for Classification\n",
        "\n",
        "Clasification bootstrapping uses the **StratifiedShuffleSplit** class to perform the splits.  This class is similar to **StratifiedKFold** for cross-validation, as the **classes are balanced so that the sampling does not affect proportions**.  To demonstrate this technique, we will attempt to predict the product column for the **jh-simple-dataset**; the following code loads this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jK8HwVfDkn4U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['age'] = zscore(df['age'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('product').drop('id')\n",
        "x = df[x_columns].values\n",
        "dummies = pd.get_dummies(df['product']) # Classification\n",
        "products = dummies.columns\n",
        "y = dummies.values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DQSViKNJkn4U"
      },
      "source": [
        "We now run this data through a number of splits specified by the SPLITS variable. We track the average error through each of these splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzu6bqDukn4U",
        "outputId": "583d468c-5d89-45e1-9353-3cfcfc795ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#1: score=0.658943, mean score=0.658943,stdev=0.000000, epochs=75, mean epochs=75, time=0:00:05.37\n",
            "#2: score=0.668390, mean score=0.663667,stdev=0.004724, epochs=71, mean epochs=73, time=0:00:05.10\n",
            "#3: score=0.687739, mean score=0.671691,stdev=0.011986, epochs=45, mean epochs=63, time=0:00:03.43\n",
            "#4: score=0.647174, mean score=0.665562,stdev=0.014847, epochs=74, mean epochs=66, time=0:00:05.37\n",
            "#5: score=0.664908, mean score=0.665431,stdev=0.013282, epochs=82, mean epochs=69, time=0:00:05.85\n",
            "#6: score=0.696934, mean score=0.670681,stdev=0.016878, epochs=68, mean epochs=69, time=0:00:04.89\n",
            "#7: score=0.719814, mean score=0.677700,stdev=0.023233, epochs=46, mean epochs=65, time=0:00:03.51\n",
            "#8: score=0.749478, mean score=0.686673,stdev=0.032184, epochs=54, mean epochs=64, time=0:00:03.98\n",
            "#9: score=0.612099, mean score=0.678387,stdev=0.038340, epochs=86, mean epochs=66, time=0:00:06.11\n",
            "#10: score=0.637532, mean score=0.674301,stdev=0.038382, epochs=77, mean epochs=67, time=0:00:05.79\n",
            "#11: score=0.677394, mean score=0.674582,stdev=0.036607, epochs=80, mean epochs=68, time=0:00:05.69\n",
            "#12: score=0.718750, mean score=0.678263,stdev=0.037113, epochs=69, mean epochs=68, time=0:00:05.00\n",
            "#13: score=0.699710, mean score=0.679913,stdev=0.036112, epochs=83, mean epochs=70, time=0:00:05.88\n",
            "#14: score=0.727427, mean score=0.683307,stdev=0.036888, epochs=74, mean epochs=70, time=0:00:05.32\n",
            "#15: score=0.663459, mean score=0.681983,stdev=0.035979, epochs=65, mean epochs=69, time=0:00:04.75\n",
            "#16: score=0.713237, mean score=0.683937,stdev=0.035649, epochs=72, mean epochs=70, time=0:00:05.21\n",
            "#17: score=0.674038, mean score=0.683355,stdev=0.034663, epochs=48, mean epochs=68, time=0:00:03.59\n",
            "#18: score=0.627811, mean score=0.680269,stdev=0.036009, epochs=60, mean epochs=68, time=0:00:04.44\n",
            "#19: score=0.631752, mean score=0.677715,stdev=0.036684, epochs=48, mean epochs=67, time=0:00:03.62\n",
            "#20: score=0.694280, mean score=0.678543,stdev=0.035937, epochs=81, mean epochs=67, time=0:00:05.98\n",
            "#21: score=0.646246, mean score=0.677005,stdev=0.035739, epochs=56, mean epochs=67, time=0:00:04.12\n",
            "#22: score=0.717188, mean score=0.678832,stdev=0.035907, epochs=71, mean epochs=67, time=0:00:05.12\n",
            "#23: score=0.586383, mean score=0.674812,stdev=0.039858, epochs=97, mean epochs=68, time=0:00:06.79\n",
            "#24: score=0.735355, mean score=0.677335,stdev=0.040852, epochs=68, mean epochs=68, time=0:00:04.94\n",
            "#25: score=0.561356, mean score=0.672696,stdev=0.046029, epochs=89, mean epochs=69, time=0:00:06.37\n",
            "#26: score=0.655146, mean score=0.672021,stdev=0.045261, epochs=76, mean epochs=69, time=0:00:05.41\n",
            "#27: score=0.695333, mean score=0.672884,stdev=0.044632, epochs=89, mean epochs=70, time=0:00:06.31\n",
            "#28: score=0.702607, mean score=0.673946,stdev=0.044174, epochs=97, mean epochs=71, time=0:00:06.83\n",
            "#29: score=0.646559, mean score=0.673001,stdev=0.043692, epochs=60, mean epochs=71, time=0:00:04.37\n",
            "#30: score=0.704994, mean score=0.674068,stdev=0.043340, epochs=83, mean epochs=71, time=0:00:06.08\n",
            "#31: score=0.757708, mean score=0.676766,stdev=0.045124, epochs=51, mean epochs=70, time=0:00:03.82\n",
            "#32: score=0.705908, mean score=0.677677,stdev=0.044702, epochs=108, mean epochs=71, time=0:00:07.66\n",
            "#33: score=0.654631, mean score=0.676978,stdev=0.044196, epochs=48, mean epochs=71, time=0:00:03.64\n",
            "#34: score=0.562658, mean score=0.673616,stdev=0.047633, epochs=120, mean epochs=72, time=0:00:08.38\n",
            "#35: score=0.501151, mean score=0.668688,stdev=0.055042, epochs=79, mean epochs=72, time=0:00:05.65\n",
            "#36: score=0.629684, mean score=0.667605,stdev=0.054649, epochs=74, mean epochs=72, time=0:00:05.32\n",
            "#37: score=0.645132, mean score=0.666998,stdev=0.054029, epochs=50, mean epochs=72, time=0:00:03.69\n",
            "#38: score=0.694525, mean score=0.667722,stdev=0.053495, epochs=54, mean epochs=71, time=0:00:03.99\n",
            "#39: score=0.777548, mean score=0.670538,stdev=0.055585, epochs=40, mean epochs=70, time=0:00:03.10\n",
            "#40: score=0.704320, mean score=0.671383,stdev=0.055139, epochs=42, mean epochs=70, time=0:00:03.22\n",
            "#41: score=0.737006, mean score=0.672983,stdev=0.055395, epochs=48, mean epochs=69, time=0:00:03.80\n",
            "#42: score=0.669103, mean score=0.672891,stdev=0.054735, epochs=61, mean epochs=69, time=0:00:04.45\n",
            "#43: score=0.692819, mean score=0.673354,stdev=0.054178, epochs=53, mean epochs=69, time=0:00:03.90\n",
            "#44: score=0.759883, mean score=0.675321,stdev=0.055089, epochs=53, mean epochs=68, time=0:00:03.90\n",
            "#45: score=0.643551, mean score=0.674615,stdev=0.054675, epochs=56, mean epochs=68, time=0:00:04.14\n",
            "#46: score=0.642815, mean score=0.673923,stdev=0.054275, epochs=74, mean epochs=68, time=0:00:05.39\n",
            "#47: score=0.688506, mean score=0.674234,stdev=0.053736, epochs=61, mean epochs=68, time=0:00:04.45\n",
            "#48: score=0.768727, mean score=0.676202,stdev=0.054860, epochs=54, mean epochs=68, time=0:00:04.00\n",
            "#49: score=0.658916, mean score=0.675850,stdev=0.054352, epochs=76, mean epochs=68, time=0:00:05.42\n",
            "#50: score=0.661577, mean score=0.675564,stdev=0.053843, epochs=56, mean epochs=68, time=0:00:04.15\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "SPLITS = 50\n",
        "\n",
        "# Bootstrap\n",
        "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1, \n",
        "                                random_state=42)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x, df['product']):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=25, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "    \n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(x_test)\n",
        "  \n",
        "    # Measure this bootstrap's log loss\n",
        "    y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
        "    score = metrics.log_loss(y_compare, pred)\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark)\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark)\n",
        "    \n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},\" +\\\n",
        "          f\"stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)},\" +\\\n",
        "          f\" time={hms_string(time_took)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IHxvxKl0kn4V"
      },
      "source": [
        "## Benchmarking\n",
        "\n",
        "Now that we've seen how to bootstrap with both classification and regression, we can start to try to optimize the hyperparameters for the **jh-simple-dataset** data.  For this example, we will encode for classification of the product column.  Evaluation will be in log loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VdKviOzhkn4V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Read the data set\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Generate dummies for job\n",
        "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
        "df.drop('job', axis=1, inplace=True)\n",
        "\n",
        "# Generate dummies for area\n",
        "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],\n",
        "               axis=1)\n",
        "df.drop('area', axis=1, inplace=True)\n",
        "\n",
        "# Missing values for income\n",
        "med = df['income'].median()\n",
        "df['income'] = df['income'].fillna(med)\n",
        "\n",
        "# Standardize ranges\n",
        "df['income'] = zscore(df['income'])\n",
        "df['aspect'] = zscore(df['aspect'])\n",
        "df['save_rate'] = zscore(df['save_rate'])\n",
        "df['age'] = zscore(df['age'])\n",
        "df['subscriptions'] = zscore(df['subscriptions'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x_columns = df.columns.drop('product').drop('id')\n",
        "x = df[x_columns].values\n",
        "dummies = pd.get_dummies(df['product']) # Classification\n",
        "products = dummies.columns\n",
        "y = dummies.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>income</th>\n",
              "      <th>aspect</th>\n",
              "      <th>subscriptions</th>\n",
              "      <th>dist_healthy</th>\n",
              "      <th>save_rate</th>\n",
              "      <th>dist_unhealthy</th>\n",
              "      <th>age</th>\n",
              "      <th>pop_dense</th>\n",
              "      <th>retail_dense</th>\n",
              "      <th>...</th>\n",
              "      <th>job_qp</th>\n",
              "      <th>job_qw</th>\n",
              "      <th>job_rn</th>\n",
              "      <th>job_sa</th>\n",
              "      <th>job_vv</th>\n",
              "      <th>job_zz</th>\n",
              "      <th>area_a</th>\n",
              "      <th>area_b</th>\n",
              "      <th>area_c</th>\n",
              "      <th>area_d</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.607550</td>\n",
              "      <td>-0.664918</td>\n",
              "      <td>-0.208449</td>\n",
              "      <td>9.017895</td>\n",
              "      <td>-0.215764</td>\n",
              "      <td>11.738935</td>\n",
              "      <td>0.854321</td>\n",
              "      <td>0.885827</td>\n",
              "      <td>0.492126</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.338053</td>\n",
              "      <td>-0.207748</td>\n",
              "      <td>0.839031</td>\n",
              "      <td>7.766643</td>\n",
              "      <td>0.196869</td>\n",
              "      <td>6.805396</td>\n",
              "      <td>1.394432</td>\n",
              "      <td>0.874016</td>\n",
              "      <td>0.342520</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.184205</td>\n",
              "      <td>1.127906</td>\n",
              "      <td>-0.208449</td>\n",
              "      <td>3.632069</td>\n",
              "      <td>-0.714362</td>\n",
              "      <td>13.671772</td>\n",
              "      <td>-0.495957</td>\n",
              "      <td>0.944882</td>\n",
              "      <td>0.724409</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.526467</td>\n",
              "      <td>-0.440815</td>\n",
              "      <td>-0.208449</td>\n",
              "      <td>5.372942</td>\n",
              "      <td>-0.542432</td>\n",
              "      <td>4.333286</td>\n",
              "      <td>1.124377</td>\n",
              "      <td>0.889764</td>\n",
              "      <td>0.444882</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>-2.851675</td>\n",
              "      <td>1.638861</td>\n",
              "      <td>1.886511</td>\n",
              "      <td>3.822477</td>\n",
              "      <td>-0.473660</td>\n",
              "      <td>5.967121</td>\n",
              "      <td>-2.116291</td>\n",
              "      <td>0.744094</td>\n",
              "      <td>0.661417</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 49 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id    income    aspect  subscriptions  dist_healthy  save_rate  \\\n",
              "0   1 -0.607550 -0.664918      -0.208449      9.017895  -0.215764   \n",
              "1   2  0.338053 -0.207748       0.839031      7.766643   0.196869   \n",
              "2   3 -0.184205  1.127906      -0.208449      3.632069  -0.714362   \n",
              "3   4 -0.526467 -0.440815      -0.208449      5.372942  -0.542432   \n",
              "4   5 -2.851675  1.638861       1.886511      3.822477  -0.473660   \n",
              "\n",
              "   dist_unhealthy       age  pop_dense  retail_dense  ...  job_qp job_qw  \\\n",
              "0       11.738935  0.854321   0.885827      0.492126  ...       0      0   \n",
              "1        6.805396  1.394432   0.874016      0.342520  ...       0      0   \n",
              "2       13.671772 -0.495957   0.944882      0.724409  ...       0      0   \n",
              "3        4.333286  1.124377   0.889764      0.444882  ...       0      0   \n",
              "4        5.967121 -2.116291   0.744094      0.661417  ...       0      0   \n",
              "\n",
              "   job_rn  job_sa  job_vv  job_zz  area_a  area_b  area_c  area_d  \n",
              "0       0       0       1       0       0       0       1       0  \n",
              "1       0       0       0       0       0       0       1       0  \n",
              "2       0       0       0       0       0       0       1       0  \n",
              "3       0       0       0       0       0       0       1       0  \n",
              "4       0       0       0       0       0       0       0       1  \n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show data (before the numpy conversion, with headers)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# show y label\n",
        "y[:5]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kKIKR9vFkn4V"
      },
      "source": [
        "I performed some optimization, and the code has the best settings that I could determine. Later in this book, we will see how we can use an automatic process to optimize the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk4w1p42kn4V",
        "outputId": "9b6c41e5-58e2-482f-c69f-bdfaf4e9172a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#1: score=0.688334, mean score=0.688334,stdev=0.000000, epochs=182,mean epochs=182, time=0:00:22.44\n",
            "#2: score=0.592043, mean score=0.640188,stdev=0.048146, epochs=275,mean epochs=228, time=0:00:31.77\n",
            "#3: score=0.626622, mean score=0.635666,stdev=0.039828, epochs=286,mean epochs=247, time=0:00:32.86\n",
            "#4: score=0.693019, mean score=0.650004,stdev=0.042502, epochs=161,mean epochs=226, time=0:00:18.27\n",
            "#5: score=0.647783, mean score=0.649560,stdev=0.038025, epochs=192,mean epochs=219, time=0:00:21.40\n",
            "#6: score=0.705468, mean score=0.658878,stdev=0.040485, epochs=128,mean epochs=204, time=0:00:14.75\n",
            "#7: score=0.606006, mean score=0.651325,stdev=0.041800, epochs=185,mean epochs=201, time=0:00:20.88\n",
            "#8: score=0.636851, mean score=0.649516,stdev=0.039392, epochs=145,mean epochs=194, time=0:00:16.51\n",
            "#9: score=0.693139, mean score=0.654363,stdev=0.039589, epochs=154,mean epochs=189, time=0:00:17.43\n",
            "#10: score=0.573316, mean score=0.646258,stdev=0.044740, epochs=273,mean epochs=198, time=0:00:30.25\n",
            "#11: score=0.652839, mean score=0.646856,stdev=0.042700, epochs=173,mean epochs=195, time=0:00:20.03\n",
            "#12: score=0.612814, mean score=0.644019,stdev=0.041951, epochs=253,mean epochs=200, time=0:00:28.00\n",
            "#13: score=0.599160, mean score=0.640569,stdev=0.042040, epochs=191,mean epochs=199, time=0:00:21.52\n",
            "#14: score=0.607547, mean score=0.638210,stdev=0.041394, epochs=187,mean epochs=198, time=0:00:20.90\n",
            "#15: score=0.685245, mean score=0.641346,stdev=0.041676, epochs=150,mean epochs=195, time=0:00:16.91\n",
            "#16: score=0.618889, mean score=0.639942,stdev=0.040717, epochs=240,mean epochs=198, time=0:00:27.21\n",
            "#17: score=0.576542, mean score=0.636213,stdev=0.042225, epochs=221,mean epochs=199, time=0:00:25.11\n",
            "#18: score=0.663932, mean score=0.637753,stdev=0.041523, epochs=277,mean epochs=204, time=0:00:31.38\n",
            "#19: score=0.595798, mean score=0.635545,stdev=0.041487, epochs=171,mean epochs=202, time=0:00:20.49\n",
            "#20: score=0.613455, mean score=0.634440,stdev=0.040722, epochs=171,mean epochs=200, time=0:00:19.51\n",
            "#21: score=0.689248, mean score=0.637050,stdev=0.041420, epochs=134,mean epochs=197, time=0:00:15.80\n",
            "#22: score=0.716402, mean score=0.640657,stdev=0.043713, epochs=129,mean epochs=194, time=0:00:14.85\n",
            "#23: score=0.608449, mean score=0.639257,stdev=0.043254, epochs=290,mean epochs=198, time=0:00:32.56\n",
            "#24: score=0.582119, mean score=0.636876,stdev=0.043855, epochs=161,mean epochs=197, time=0:00:18.27\n",
            "#25: score=0.662207, mean score=0.637889,stdev=0.043255, epochs=188,mean epochs=196, time=0:00:22.45\n",
            "#26: score=0.706106, mean score=0.640513,stdev=0.044397, epochs=182,mean epochs=196, time=0:00:20.48\n",
            "#27: score=0.585504, mean score=0.638476,stdev=0.044789, epochs=245,mean epochs=197, time=0:00:28.86\n",
            "#28: score=0.597264, mean score=0.637004,stdev=0.044642, epochs=163,mean epochs=196, time=0:00:18.22\n",
            "#29: score=0.521416, mean score=0.633018,stdev=0.048672, epochs=243,mean epochs=198, time=0:00:26.87\n",
            "#30: score=0.691524, mean score=0.634968,stdev=0.048993, epochs=182,mean epochs=197, time=0:00:20.22\n",
            "#31: score=0.611064, mean score=0.634197,stdev=0.048381, epochs=202,mean epochs=197, time=0:00:22.37\n",
            "#32: score=0.634543, mean score=0.634208,stdev=0.047619, epochs=221,mean epochs=198, time=0:00:26.92\n",
            "#33: score=0.674035, mean score=0.635415,stdev=0.047386, epochs=220,mean epochs=199, time=0:00:25.67\n",
            "#34: score=0.663516, mean score=0.636241,stdev=0.046925, epochs=176,mean epochs=198, time=0:00:19.89\n",
            "#35: score=0.671466, mean score=0.637248,stdev=0.046621, epochs=197,mean epochs=198, time=0:00:23.48\n",
            "#36: score=0.711107, mean score=0.639299,stdev=0.047544, epochs=183,mean epochs=198, time=0:00:23.57\n",
            "#37: score=0.689369, mean score=0.640653,stdev=0.047595, epochs=150,mean epochs=196, time=0:00:18.85\n",
            "#38: score=0.762889, mean score=0.643869,stdev=0.050878, epochs=130,mean epochs=195, time=0:00:15.90\n",
            "#39: score=0.613107, mean score=0.643081,stdev=0.050456, epochs=266,mean epochs=196, time=0:00:32.44\n",
            "#40: score=0.653402, mean score=0.643339,stdev=0.049847, epochs=181,mean epochs=196, time=0:00:22.27\n",
            "#41: score=0.717994, mean score=0.645159,stdev=0.050564, epochs=144,mean epochs=195, time=0:00:17.87\n",
            "#42: score=0.710736, mean score=0.646721,stdev=0.050949, epochs=167,mean epochs=194, time=0:00:19.22\n",
            "#43: score=0.575446, mean score=0.645063,stdev=0.051487, epochs=228,mean epochs=195, time=0:00:25.21\n",
            "#44: score=0.666492, mean score=0.645550,stdev=0.050998, epochs=133,mean epochs=193, time=0:00:14.93\n",
            "#45: score=0.677913, mean score=0.646269,stdev=0.050654, epochs=178,mean epochs=193, time=0:00:19.87\n",
            "#46: score=0.646247, mean score=0.646269,stdev=0.050100, epochs=181,mean epochs=193, time=0:00:20.50\n",
            "#47: score=0.659512, mean score=0.646551,stdev=0.049601, epochs=158,mean epochs=192, time=0:00:18.01\n",
            "#48: score=0.660456, mean score=0.646840,stdev=0.049122, epochs=263,mean epochs=193, time=0:00:29.99\n",
            "#49: score=0.514566, mean score=0.644141,stdev=0.052091, epochs=252,mean epochs=195, time=0:00:27.59\n",
            "#50: score=0.660214, mean score=0.644462,stdev=0.051617, epochs=240,mean epochs=196, time=0:00:26.46\n",
            "#51: score=0.590253, mean score=0.643399,stdev=0.051658, epochs=318,mean epochs=198, time=0:00:37.13\n",
            "#52: score=0.630195, mean score=0.643145,stdev=0.051191, epochs=213,mean epochs=198, time=0:00:26.75\n",
            "#53: score=0.577004, mean score=0.641898,stdev=0.051498, epochs=216,mean epochs=199, time=0:00:27.38\n",
            "#54: score=0.683487, mean score=0.642668,stdev=0.051326, epochs=203,mean epochs=199, time=0:00:24.06\n",
            "#55: score=0.640053, mean score=0.642620,stdev=0.050859, epochs=238,mean epochs=199, time=0:00:29.47\n",
            "#56: score=0.672945, mean score=0.643162,stdev=0.050562, epochs=147,mean epochs=198, time=0:00:17.97\n",
            "#57: score=0.678472, mean score=0.643781,stdev=0.050331, epochs=142,mean epochs=197, time=0:00:16.95\n",
            "#58: score=0.617813, mean score=0.643333,stdev=0.050009, epochs=184,mean epochs=197, time=0:00:21.39\n",
            "#59: score=0.598691, mean score=0.642577,stdev=0.049917, epochs=226,mean epochs=198, time=0:00:25.15\n",
            "#60: score=0.725172, mean score=0.643953,stdev=0.050616, epochs=134,mean epochs=197, time=0:00:15.15\n",
            "#61: score=0.721068, mean score=0.645218,stdev=0.051146, epochs=154,mean epochs=196, time=0:00:18.06\n",
            "#62: score=0.713474, mean score=0.646318,stdev=0.051455, epochs=129,mean epochs=195, time=0:00:14.60\n",
            "#63: score=0.551398, mean score=0.644812,stdev=0.052406, epochs=227,mean epochs=195, time=0:00:26.51\n",
            "#64: score=0.751301, mean score=0.646476,stdev=0.053646, epochs=127,mean epochs=194, time=0:00:15.51\n",
            "#65: score=0.667682, mean score=0.646802,stdev=0.053295, epochs=139,mean epochs=193, time=0:00:17.46\n",
            "#66: score=0.669074, mean score=0.647139,stdev=0.052960, epochs=240,mean epochs=194, time=0:00:26.54\n",
            "#67: score=0.682150, mean score=0.647662,stdev=0.052734, epochs=176,mean epochs=194, time=0:00:20.73\n",
            "#68: score=0.648793, mean score=0.647679,stdev=0.052345, epochs=180,mean epochs=194, time=0:00:20.92\n",
            "#69: score=0.661021, mean score=0.647872,stdev=0.051989, epochs=171,mean epochs=193, time=0:00:19.58\n",
            "#70: score=0.622445, mean score=0.647509,stdev=0.051705, epochs=197,mean epochs=193, time=0:00:22.33\n",
            "#71: score=0.716896, mean score=0.648486,stdev=0.051986, epochs=134,mean epochs=192, time=0:00:15.84\n",
            "#72: score=0.636909, mean score=0.648325,stdev=0.051642, epochs=191,mean epochs=192, time=0:00:21.89\n",
            "#73: score=0.621012, mean score=0.647951,stdev=0.051385, epochs=194,mean epochs=192, time=0:00:22.31\n",
            "#74: score=0.676035, mean score=0.648331,stdev=0.051140, epochs=231,mean epochs=193, time=0:00:27.25\n",
            "#75: score=0.676062, mean score=0.648700,stdev=0.050897, epochs=205,mean epochs=193, time=0:00:25.74\n",
            "#76: score=0.651577, mean score=0.648738,stdev=0.050562, epochs=141,mean epochs=192, time=0:00:16.29\n",
            "#77: score=0.750375, mean score=0.650058,stdev=0.051534, epochs=151,mean epochs=192, time=0:00:18.17\n",
            "#78: score=0.655545, mean score=0.650128,stdev=0.051206, epochs=182,mean epochs=192, time=0:00:21.59\n",
            "#79: score=0.744191, mean score=0.651319,stdev=0.051956, epochs=219,mean epochs=192, time=0:00:26.33\n",
            "#80: score=0.589976, mean score=0.650552,stdev=0.052078, epochs=195,mean epochs=192, time=0:00:22.31\n",
            "#81: score=0.716575, mean score=0.651367,stdev=0.052267, epochs=125,mean epochs=191, time=0:00:14.29\n",
            "#82: score=0.686174, mean score=0.651792,stdev=0.052088, epochs=174,mean epochs=191, time=0:00:19.95\n",
            "#83: score=0.603588, mean score=0.651211,stdev=0.052039, epochs=168,mean epochs=191, time=0:00:19.14\n",
            "#84: score=0.661541, mean score=0.651334,stdev=0.051741, epochs=255,mean epochs=192, time=0:00:28.58\n",
            "#85: score=0.600334, mean score=0.650734,stdev=0.051729, epochs=189,mean epochs=191, time=0:00:21.18\n",
            "#86: score=0.627513, mean score=0.650464,stdev=0.051487, epochs=200,mean epochs=192, time=0:00:22.66\n",
            "#87: score=0.687428, mean score=0.650889,stdev=0.051342, epochs=196,mean epochs=192, time=0:00:22.46\n",
            "#88: score=0.654579, mean score=0.650931,stdev=0.051051, epochs=172,mean epochs=191, time=0:00:19.58\n",
            "#89: score=0.646813, mean score=0.650885,stdev=0.050765, epochs=146,mean epochs=191, time=0:00:16.67\n",
            "#90: score=0.622695, mean score=0.650571,stdev=0.050569, epochs=219,mean epochs=191, time=0:00:24.34\n",
            "#91: score=0.649392, mean score=0.650558,stdev=0.050290, epochs=174,mean epochs=191, time=0:00:19.80\n",
            "#92: score=0.616144, mean score=0.650184,stdev=0.050143, epochs=239,mean epochs=191, time=0:00:27.40\n",
            "#93: score=0.569064, mean score=0.649312,stdev=0.050570, epochs=172,mean epochs=191, time=0:00:19.50\n",
            "#94: score=0.608134, mean score=0.648874,stdev=0.050477, epochs=215,mean epochs=192, time=0:00:25.42\n",
            "#95: score=0.672935, mean score=0.649127,stdev=0.050271, epochs=225,mean epochs=192, time=0:00:25.81\n",
            "#96: score=0.714234, mean score=0.649806,stdev=0.050443, epochs=150,mean epochs=191, time=0:00:17.68\n",
            "#97: score=0.654376, mean score=0.649853,stdev=0.050185, epochs=142,mean epochs=191, time=0:00:16.36\n",
            "#98: score=0.725903, mean score=0.650629,stdev=0.050510, epochs=140,mean epochs=190, time=0:00:17.18\n",
            "#99: score=0.669009, mean score=0.650814,stdev=0.050287, epochs=183,mean epochs=190, time=0:00:20.60\n",
            "#100: score=0.557590, mean score=0.649882,stdev=0.050888, epochs=332,mean epochs=192, time=0:00:37.49\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow.keras.initializers\n",
        "import statistics\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
        "\n",
        "SPLITS = 100\n",
        "\n",
        "# Bootstrap\n",
        "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1)\n",
        "\n",
        "# Track progress\n",
        "mean_benchmark = []\n",
        "epochs_needed = []\n",
        "num = 0\n",
        "\n",
        "# Loop through samples\n",
        "for train, test in boot.split(x,df['product']):\n",
        "    start_time = time.time()\n",
        "    num+=1\n",
        "\n",
        "    # Split train and test\n",
        "    x_train = x[train]\n",
        "    y_train = y[train]\n",
        "    x_test = x[test]\n",
        "    y_test = y[test]\n",
        "\n",
        "    # Construct neural network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, input_dim=x.shape[1], activation=PReLU(), \\\n",
        "        kernel_regularizer=regularizers.l2(1e-4))) # Hidden 1\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100, activation=PReLU(), \\\n",
        "        activity_regularizer=regularizers.l2(1e-4))) # Hidden 2\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100, activation=PReLU(), \\\n",
        "        activity_regularizer=regularizers.l2(1e-4)\n",
        "    )) # Hidden 3\n",
        "#    model.add(Dropout(0.5)) - Usually better performance \n",
        "# without dropout on final layer\n",
        "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=100, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "    # Train on the bootstrap sample\n",
        "    model.fit(x_train,y_train,validation_data=(x_test,y_test), \\\n",
        "              callbacks=[monitor],verbose=0,epochs=1000)\n",
        "    epochs = monitor.stopped_epoch\n",
        "    epochs_needed.append(epochs)\n",
        "    \n",
        "    # Predict on the out of boot (validation)\n",
        "    pred = model.predict(x_test)\n",
        "  \n",
        "    # Measure this bootstrap's log loss\n",
        "    y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
        "    score = metrics.log_loss(y_compare, pred)\n",
        "    mean_benchmark.append(score)\n",
        "    m1 = statistics.mean(mean_benchmark)\n",
        "    m2 = statistics.mean(epochs_needed)\n",
        "    mdev = statistics.pstdev(mean_benchmark)\n",
        "    \n",
        "    # Record this iteration\n",
        "    time_took = time.time() - start_time\n",
        "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},\"\n",
        "          f\"stdev={mdev:.6f}, epochs={epochs},\"\n",
        "          f\"mean epochs={int(m2)}, time={hms_string(time_took)}\")"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of t81_558_class_05_5_bootstrap.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
