{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSIM-PITWYFa"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_14_01_automl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDTXd8-Lmp8Q"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 14: Other Neural Network Techniques**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncNrAEpzmp8S"
   },
   "source": [
    "# Module 14 Video Material\n",
    "\n",
    "* **Part 14.1: What is AutoML** [[Video]](https://www.youtube.com/watch?v=1mB_5iurqzw&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_14_01_automl.ipynb)\n",
    "* Part 14.2: Using Denoising AutoEncoders in Keras [[Video]](https://www.youtube.com/watch?v=4bTSu6_fucc&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_14_02_auto_encode.ipynb)\n",
    "* Part 14.3: Training an Intrusion Detection System with KDD99 [[Video]](https://www.youtube.com/watch?v=1ySn6h2A68I&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_14_03_anomaly.ipynb)\n",
    "* Part 14.4: Anomaly Detection in Keras [[Video]](https://www.youtube.com/watch?v=VgyKQ5MTDFc&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_14_04_ids_kdd99.ipynb)\n",
    "* Part 14.5: The Deep Learning Technologies I am Excited About [[Video]]() [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_14_05_new_tech.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lux_6KOXMU94"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fU9UhAxTmp8S",
    "outputId": "8b05ccdb-10f3-460b-c356-f299191aae47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "# Detect Colab if present\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q09yMGGcmp9N"
   },
   "source": [
    "# Part 14.1: What is AutoML\n",
    "\n",
    "Automatic Machine Learning (AutoML) attempts to use machine learning to automate itself.  Data is passed to the AutoML application in raw form, and models are automatically generated.\n",
    "\n",
    "## AutoML from your Local Computer\n",
    "\n",
    "The following AutoML applications are free:\n",
    "\n",
    "* [AutoKeras](https://autokeras.com/)\n",
    "* [Auto-SKLearn](https://automl.github.io/auto-sklearn/master/)\n",
    "* [Auto PyTorch](https://github.com/automl/Auto-PyTorch)\n",
    "* [TPOT](http://epistasislab.github.io/tpot/)\n",
    "\n",
    "The following AutoML applications are commercial:\n",
    "\n",
    "* [Rapid Miner](https://rapidminer.com/educational-program/) - Free student version available.\n",
    "* [Dataiku](https://www.dataiku.com/dss/editions/) - Free community version available.\n",
    "* [DataRobot](https://www.datarobot.com/) - Commercial\n",
    "* [H2O Driverless](https://www.h2o.ai/products/h2o-driverless-ai/) - Commercial\n",
    "\n",
    "### AutoML from Google Cloud\n",
    "\n",
    "There are also cloud-hosted AutoML platforms:\n",
    "\n",
    "* [Google Cloud AutoML Tutorial](https://cloud.google.com/vision/automl/docs/tutorial)\n",
    "* [Azure AutoML](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-automated-ml-for-ml-models)\n",
    "\n",
    "This module will show how to use [AutoKeras](https://autokeras.com/). First, we download the paperclips counting dataset that you saw previously in this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8ixjIi5p8Uy",
    "outputId": "c4997f98-7a51-4aa7-b25b-82af2cc34c10"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://github.com/jeffheaton/data-mirror/\"\n",
    "DOWNLOAD_SOURCE = URL+\"releases/download/v1/paperclips.zip\"\n",
    "DOWNLOAD_NAME = DOWNLOAD_SOURCE[DOWNLOAD_SOURCE.rfind('/')+1:]\n",
    "\n",
    "if COLAB:\n",
    "  PATH = \"/content\"\n",
    "else:\n",
    "  # I used this locally on my machine, you may need different\n",
    "  PATH = \"/home/adeng/Py_workingdir/datasets/\"\n",
    "\n",
    "EXTRACT_TARGET = os.path.join(PATH,\"clips\")\n",
    "SOURCE = os.path.join(EXTRACT_TARGET, \"paperclips\")\n",
    "\n",
    "# # Download paperclip data\n",
    "# !wget -O {os.path.join(PATH,DOWNLOAD_NAME)} {DOWNLOAD_SOURCE}\n",
    "# !mkdir -p {SOURCE}\n",
    "# !mkdir -p {TARGET}\n",
    "# !mkdir -p {EXTRACT_TARGET}\n",
    "# !unzip -o -j -d {SOURCE} {os.path.join(PATH, DOWNLOAD_NAME)} >/dev/null\n",
    "\n",
    "# Process training data \n",
    "df_train = pd.read_csv(os.path.join(SOURCE, \"train.csv\"))\n",
    "df_train['filename'] = \"clips-\" + df_train.id.astype(str) + \".jpg\"\n",
    "\n",
    "# Use only the first 1000 images\n",
    "df_train = df_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjU8vkP2ohHM"
   },
   "source": [
    "One limitation of AutoKeras is that it cannot directly utilize generators. **Without resorting to complex techniques, all training data must reside in RAM.** We will use the following code to load the image data to RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYiMObEJsoof",
    "outputId": "779f7e38-4796-44cc-ebf8-6751f0fb75d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 586.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# HIDE OUTPUT\n",
    "import tensorflow as tf\n",
    "# import keras_preprocessing\n",
    "import glob, os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "IMG_SHAPE = (128,128)\n",
    "\n",
    "def load_images(files, img_shape):\n",
    "  cnt = len(files)\n",
    "  x = np.zeros((cnt,)+img_shape+(3,))\n",
    "  i = 0\n",
    "  for file in tqdm.tqdm(files):\n",
    "    img = Image.open(file)\n",
    "    img = img.resize(img_shape)\n",
    "    img = np.array(img)\n",
    "    img = img/255\n",
    "    x[i,:,:,:] = img\n",
    "    i+=1\n",
    "  return x\n",
    "\n",
    "images = [os.path.join(SOURCE,x) for x in df_train.filename]\n",
    "x = load_images(images, IMG_SHAPE)\n",
    "y = df_train.clip_count.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKWkNJOzjD09"
   },
   "source": [
    "## Using AutoKeras\n",
    "\n",
    "[AutoKeras](https://autokeras.com/) is an AutoML system based on Keras. The goal of AutoKeras is to make machine learning accessible to everyone. [DATA Lab](http://people.tamu.edu/~guangzhou92/Data_Lab/) develops it at [Texas A&M University](https://www.tamu.edu/). We will see how to provide the paperclips dataset to AutoKeras and create an automatically tuned Keras deep learning model from this dataset. This automatic process frees you from choosing layer types and neuron counts.\n",
    "\n",
    "We begin by installing AutoKeras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jI_4yo8Rmj1",
    "outputId": "748ec093-a166-4cb2-9b2a-f89711586e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autokeras\n",
      "  Downloading autokeras-1.1.0-py3-none-any.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from autokeras) (23.1)\n",
      "Collecting tensorflow>=2.8.0 (from autokeras)\n",
      "  Obtaining dependency information for tensorflow>=2.8.0 from https://files.pythonhosted.org/packages/c2/20/b15abac0be474f12cf51a104c9dd935b053081b502c103e9e947e8be7b84/tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting keras-tuner>=1.1.0 (from autokeras)\n",
      "  Obtaining dependency information for keras-tuner>=1.1.0 from https://files.pythonhosted.org/packages/ff/da/39a5389652e31b135d01833ff52a9cbb6538326150df4fc9f6f28cbfb700/keras_tuner-1.4.5-py3-none-any.whl.metadata\n",
      "  Downloading keras_tuner-1.4.5-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting keras-nlp>=0.4.0 (from autokeras)\n",
      "  Obtaining dependency information for keras-nlp>=0.4.0 from https://files.pythonhosted.org/packages/13/fc/258d2a78faaacceeaab2be1a64fbf69f77bd56d55758cd4188db3b0f71e3/keras_nlp-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading keras_nlp-0.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pandas in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from autokeras) (1.4.4)\n",
      "Collecting keras-core (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for keras-core from https://files.pythonhosted.org/packages/33/18/5280fbfd70485fae8088a2f44647ea0d82c7dc9b80635ae2e7c578f785e0/keras_core-0.1.5-py3-none-any.whl.metadata\n",
      "  Downloading keras_core-0.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: absl-py in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from keras-nlp>=0.4.0->autokeras) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from keras-nlp>=0.4.0->autokeras) (1.23.5)\n",
      "Requirement already satisfied: regex in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from keras-nlp>=0.4.0->autokeras) (2023.8.8)\n",
      "Collecting rich (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/be/2a/4e62ff633612f746f88618852a626bbe24226eba5e7ac90e91dcfd6a414e/rich-13.6.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tensorflow-text (from keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-text from https://files.pythonhosted.org/packages/70/f3/a2e79de3c1255313f722c071602bc36b4ac52a1199d3b82dc0d641c2f9b3/tensorflow_text-2.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow_text-2.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: requests in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from keras-tuner>=1.1.0->autokeras) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner>=1.1.0->autokeras)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for flatbuffers>=23.1.21 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (1.48.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (2.10.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/ea/df/55525e489c43f9dbb6c8ea27d8a567b3dcd18a22f3c45483055f5ca6611d/libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow>=2.8.0->autokeras)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (2.1.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow>=2.8.0->autokeras)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/25/f6/0f259f41abaa489f185e16d397d5f5a5973970d4677c7d39456cea6f4453/tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from pandas->autokeras) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from pandas->autokeras) (2023.3.post1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (2.6.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/02/52/fb9e51fba47951aabd7a6b25e41d73eae94208ccf62d886168096941a781/tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (2.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.12.7)\n",
      "Collecting namex (from keras-core->keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting dm-tree (from keras-core->keras-nlp>=0.4.0->autokeras)\n",
      "  Using cached dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from rich->keras-nlp>=0.4.0->autokeras) (2.16.1)\n",
      "Collecting tensorflow-hub>=0.8.0 (from tensorflow-text->keras-nlp>=0.4.0->autokeras)\n",
      "  Obtaining dependency information for tensorflow-hub>=0.8.0 from https://files.pythonhosted.org/packages/6e/1a/fbae76f4057b9bcdf9468025d7a8ca952dec14bfafb9fc0b1e4244ce212f/tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (4.7.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/39/7c/2e4fa55a99f83ef9ef229ac5d59c44ceb90e2d0145711590c0fa39669f32/google_auth-2.23.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (6.8.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/adeng/miniconda3/envs/tensorflow/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (3.2.1)\n",
      "Downloading keras_nlp-0.6.1-py3-none-any.whl (573 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.5/573.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras_tuner-1.4.5-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.6/479.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:02\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Downloading keras_core-0.1.5-py3-none-any.whl (924 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.6/924.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_text-2.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, kt-legacy, flatbuffers, dm-tree, typing-extensions, tensorflow-io-gcs-filesystem, tensorflow-hub, tensorflow-estimator, tensorboard-data-server, mdurl, keras, markdown-it-py, google-auth, rich, google-auth-oauthlib, tensorboard, keras-core, tensorflow, keras-tuner, tensorflow-text, keras-nlp, autokeras\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.6.0\n",
      "    Uninstalling google-auth-2.6.0:\n",
      "      Successfully uninstalled google-auth-2.6.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.4\n",
      "    Uninstalling google-auth-oauthlib-0.4.4:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.0\n",
      "    Uninstalling tensorboard-2.10.0:\n",
      "      Successfully uninstalled tensorboard-2.10.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed autokeras-1.1.0 dm-tree-0.1.8 flatbuffers-23.5.26 google-auth-2.23.3 google-auth-oauthlib-1.0.0 keras-2.13.1 keras-core-0.1.5 keras-nlp-0.6.1 keras-tuner-1.4.5 kt-legacy-1.0.5 libclang-16.0.6 markdown-it-py-3.0.0 mdurl-0.1.2 namex-0.0.7 rich-13.6.0 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-hub-0.15.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-text-2.13.0 typing-extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# HIDE OUTPUT\n",
    "%pip install autokeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9MOm41vpka9"
   },
   "source": [
    "AutoKeras contains several [examples](https://autokeras.com/tutorial/overview/) demonstrating image, tabular, and time-series data. We will make use of the **ImageRegressor**. Refer to the AutoKeras documentation for other classifiers and regressors to fit specific uses.  \n",
    "\n",
    "We define several variables to determine the AutoKeras operation:\n",
    "\n",
    "* **MAX_TRIALS** - Determines how many different models to see.\n",
    "* **SEED** - You can try different random seeds to obtain different results.\n",
    "* **VAL_SPLIT** - What percent of the dataset should we use for validation.\n",
    "* **EPOCHS** - How many epochs to try each model for training.\n",
    "* **BATCH_SIZE** - Training batch size.\n",
    "\n",
    "Setting MAX_TRIALS and EPOCHS will have a great impact on your total runtime. You must balance how many models to try (MAX_TRIALS) and how deeply to try to train each (EPOCHS). AutoKeras utilize early stopping, so setting EPOCHS too high will mean early stopping will prevent you from reaching the EPOCHS number of epochs. \n",
    "\n",
    "**One strategy is to do a broad, shallow search. Set TRIALS high and EPOCHS low.** The resulting model likely has the best hyperparameters. **Finally, train this resulting model fully.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZ_Qqr2qJvam",
    "outputId": "f6a5266a-c56a-4c92-c903-347807ebbacb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 45m 52s]\n",
      "val_loss: 1445.5208740234375\n",
      "\n",
      "Best val_loss So Far: 40.25547409057617\n",
      "Total elapsed time: 03h 30m 35s\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 68s 2s/step - loss: 133067.2344 - mean_squared_error: 133067.2344\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 5523.8145 - mean_squared_error: 5523.8145\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 386.9892 - mean_squared_error: 386.9892\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 119.3479 - mean_squared_error: 119.3479\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 69.9707 - mean_squared_error: 69.9707\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 50.9567 - mean_squared_error: 50.9567\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 46.5011 - mean_squared_error: 46.5011\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 48.4602 - mean_squared_error: 48.4602\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 49.2169 - mean_squared_error: 49.2169\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 66s 2s/step - loss: 42.1309 - mean_squared_error: 42.1309\n",
      "INFO:tensorflow:Assets written to: ./image_regressor/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./image_regressor/best_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 67s 2s/step - loss: 45.8611 - mean_squared_error: 45.8611\n",
      "[45.861053466796875, 45.861053466796875]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import autokeras as ak\n",
    "\n",
    "MAX_TRIALS = 20\n",
    "SEED = 42\n",
    "VAL_SPLIT = 0.1\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "auto_reg = ak.ImageRegressor(overwrite=True, \n",
    "  max_trials=MAX_TRIALS,\n",
    "  seed=42)\n",
    "auto_reg.fit(x, y, validation_split=VAL_SPLIT, batch_size=BATCH_SIZE, \n",
    "        epochs=EPOCHS)\n",
    "print(auto_reg.evaluate(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autokeras CPU training time\n",
    "For the above setting using autokeras (CPU), total time it took is 224 minutes = 3.73 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My1KzK2ApqCz"
   },
   "source": [
    "We can now display the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJGhmWHNLhZN",
    "outputId": "e71fa5b6-ffa3-4c1a-ac4e-77de9b217dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autokeras.tasks.image.ImageRegressor'>\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " cast_to_float32 (CastToFlo  (None, 128, 128, 3)       0         \n",
      " at32)                                                           \n",
      "                                                                 \n",
      " resizing (Resizing)         (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, None, None, 2048   23587712  \n",
      "                             )                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " regression_head_1 (Dense)   (None, 1)                 100353    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23688065 (90.36 MB)\n",
      "Trainable params: 100353 (392.00 KB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(type(auto_reg))\n",
    "model = auto_reg.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxmVTxKWpvL9"
   },
   "source": [
    "This top model can be saved and either utilized or trained further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtYaXjNAQ3dT",
    "outputId": "4e6cc42e-4212-491a-9b06-b927a5866e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.src.engine.functional.Functional'>\n",
      "INFO:tensorflow:Assets written to: model_autokeras/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_autokeras/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 70s 2s/step - loss: 45.8611 - mean_squared_error: 45.8611\n",
      "[45.861053466796875, 45.861053466796875]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "print(type(model))  \n",
    "\n",
    "try:\n",
    "    model.save(\"model_autokeras\", save_format=\"tf\") # first attempt to save as tf format\n",
    "except Exception:\n",
    "    model.save(\"model_autokeras.h5\")\n",
    "\n",
    "\n",
    "loaded_model = load_model(\"model_autokeras\",\\\n",
    "    custom_objects=ak.CUSTOM_OBJECTS)\n",
    "print(loaded_model.evaluate(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x  4 adeng adeng     4096 Oct 15 17:22 model_autokeras\n"
     ]
    }
   ],
   "source": [
    "!ls -l | grep -i 'model_autokeras'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "Final of base-auto.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
